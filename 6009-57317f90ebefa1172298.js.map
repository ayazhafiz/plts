{"version":3,"file":"6009-57317f90ebefa1172298.js","mappings":"yKAIO,IAAIA,EAAO,CAChBC,SAAU,CACRC,YAAa,WAGfC,SAAU,CAAC,CAAC,IAAK,MACjBC,iBAAkB,CAAC,CACjBC,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,MAETC,iBAAkB,CAAC,CACjBF,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,KACN,CACDD,KAAM,IACNC,MAAO,MAETE,QAAS,CACPC,QAAS,CACPC,MAAO,IAAIC,OAAO,oCAClBC,IAAK,IAAID,OAAO,0CAIXE,EAAW,CAGpBC,aAAc,SACdC,YAAY,EACZC,SAAU,CAAC,QAAS,MAAO,SAAU,QAAS,YAAa,MAAO,MAAO,OAAQ,WAAY,OAAQ,MACrGC,aAAc,CAAC,SAAU,SAAU,MAAO,OAAQ,OAAQ,QAAS,QACnEC,UAAW,CAAC,OAAQ,UAAW,QAAS,KAAM,KAAM,KAAM,MAAO,MAAO,QAAS,WAAY,aAAc,WAAY,aAAc,QAAS,SAAU,UAAW,KAAM,KAAM,aAE/KC,QAAS,wBAETC,UAAW,CACTC,KAAM,CACN,CAAC,8BAA+B,CAAC,GAAI,YACrC,CAAC,IAAK,CACJC,MAAO,mBACPC,QAAS,QACTC,KAAM,uBACJ,CAAC,OAAQ,CACXF,MAAO,UACPC,QAAS,QACTC,KAAM,6BACJ,CAAC,QAAS,CACZF,MAAO,UACPC,QAAS,QACTC,KAAM,YACJ,CAAC,IAAK,CACRF,MAAO,YACPC,QAAS,QACTC,KAAM,6BAER,CAAC,gBAAiB,CAChBC,MAAO,CACL,aAAc,WACd,gBAAiB,eACjB,YAAa,UACb,WAAY,gBAGhB,CACEC,QAAS,eAEX,CAAC,aAAc,aAAc,CAAC,mBAAoB,aAAc,CAAC,WAAY,aAC7E,CAAC,gBAAiB,iBAAkB,CAAC,2BAA4B,gBAAiB,CAAC,oBAAqB,cAAe,CAAC,MAAO,UAC/H,CAAC,QAAS,cACVC,kBAAmB,CAAC,CAAC,UAAW,cAAe,CAAC,IAAK,CACnDL,MAAO,mBACPC,QAAS,SACTC,KAAM,UAERI,8BAA+B,CAAC,CAAC,IAAK,aAAc,CAAC,IAAK,CACxDN,MAAO,QACPE,KAAM,sBAERK,wBAAyB,CAAC,CACxBH,QAAS,eACR,CAAC,IAAK,CACPJ,MAAO,YACPE,KAAM,qBACJ,CAAC,UAAW,cAAe,CAAC,KAAM,CACpCF,MAAO,YACPC,QAAS,SACTC,KAAM,UAERM,gBAAiB,CAAC,CAAC,UAAW,cAAe,CAAC,KAAM,CAClDR,MAAO,YACPC,QAAS,SACTC,KAAM,UAERO,OAAQ,CAAC,CACPL,QAAS,eACR,CAAC,IAAK,aAAc,CAAC,gBAAiB,CACvCJ,MAAO,gBACPC,QAAS,SACTC,KAAM,UAERQ,WAAY,CAAC,CAAC,aAAc","sources":["webpack://www/../node_modules/monaco-editor/esm/vs/basic-languages/lexon/lexon.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\r\n *  Copyright (c) Microsoft Corporation. All rights reserved.\r\n *  Licensed under the MIT License. See License.txt in the project root for license information.\r\n *--------------------------------------------------------------------------------------------*/\nexport var conf = {\n  comments: {\n    lineComment: 'COMMENT' // blockComment: ['COMMENT', '.'],\n\n  },\n  brackets: [['(', ')']],\n  autoClosingPairs: [{\n    open: '{',\n    close: '}'\n  }, {\n    open: '[',\n    close: ']'\n  }, {\n    open: '(',\n    close: ')'\n  }, {\n    open: '\"',\n    close: '\"'\n  }, {\n    open: ':',\n    close: '.'\n  }],\n  surroundingPairs: [{\n    open: '{',\n    close: '}'\n  }, {\n    open: '[',\n    close: ']'\n  }, {\n    open: '(',\n    close: ')'\n  }, {\n    open: '`',\n    close: '`'\n  }, {\n    open: '\"',\n    close: '\"'\n  }, {\n    open: \"'\",\n    close: \"'\"\n  }, {\n    open: ':',\n    close: '.'\n  }],\n  folding: {\n    markers: {\n      start: new RegExp('^\\\\s*(::\\\\s*|COMMENT\\\\s+)#region'),\n      end: new RegExp('^\\\\s*(::\\\\s*|COMMENT\\\\s+)#endregion')\n    }\n  }\n};\nexport var language = {\n  // Set defaultToken to invalid to see what you do not tokenize yet\n  // defaultToken: 'invalid',\n  tokenPostfix: '.lexon',\n  ignoreCase: true,\n  keywords: ['lexon', 'lex', 'clause', 'terms', 'contracts', 'may', 'pay', 'pays', 'appoints', 'into', 'to'],\n  typeKeywords: ['amount', 'person', 'key', 'time', 'date', 'asset', 'text'],\n  operators: ['less', 'greater', 'equal', 'le', 'gt', 'or', 'and', 'add', 'added', 'subtract', 'subtracted', 'multiply', 'multiplied', 'times', 'divide', 'divided', 'is', 'be', 'certified'],\n  // we include these common regular expressions\n  symbols: /[=><!~?:&|+\\-*\\/\\^%]+/,\n  // The main tokenizer for our languages\n  tokenizer: {\n    root: [// comment\n    [/^(\\s*)(comment:?(?:\\s.*|))$/, ['', 'comment']], // special identifier cases\n    [/\"/, {\n      token: 'identifier.quote',\n      bracket: '@open',\n      next: '@quoted_identifier'\n    }], ['LEX$', {\n      token: 'keyword',\n      bracket: '@open',\n      next: '@identifier_until_period'\n    }], ['LEXON', {\n      token: 'keyword',\n      bracket: '@open',\n      next: '@semver'\n    }], [':', {\n      token: 'delimiter',\n      bracket: '@open',\n      next: '@identifier_until_period'\n    }], // identifiers and keywords\n    [/[a-z_$][\\w$]*/, {\n      cases: {\n        '@operators': 'operator',\n        '@typeKeywords': 'keyword.type',\n        '@keywords': 'keyword',\n        '@default': 'identifier'\n      }\n    }], // whitespace\n    {\n      include: '@whitespace'\n    }, // delimiters and operators\n    [/[{}()\\[\\]]/, '@brackets'], [/[<>](?!@symbols)/, '@brackets'], [/@symbols/, 'delimiter'], // numbers\n    [/\\d*\\.\\d*\\.\\d*/, 'number.semver'], [/\\d*\\.\\d+([eE][\\-+]?\\d+)?/, 'number.float'], [/0[xX][0-9a-fA-F]+/, 'number.hex'], [/\\d+/, 'number'], // delimiter: after number because of .\\d floats\n    [/[;,.]/, 'delimiter']],\n    quoted_identifier: [[/[^\\\\\"]+/, 'identifier'], [/\"/, {\n      token: 'identifier.quote',\n      bracket: '@close',\n      next: '@pop'\n    }]],\n    space_identifier_until_period: [[':', 'delimiter'], [' ', {\n      token: 'white',\n      next: '@identifier_rest'\n    }]],\n    identifier_until_period: [{\n      include: '@whitespace'\n    }, [':', {\n      token: 'delimiter',\n      next: '@identifier_rest'\n    }], [/[^\\\\.]+/, 'identifier'], [/\\./, {\n      token: 'delimiter',\n      bracket: '@close',\n      next: '@pop'\n    }]],\n    identifier_rest: [[/[^\\\\.]+/, 'identifier'], [/\\./, {\n      token: 'delimiter',\n      bracket: '@close',\n      next: '@pop'\n    }]],\n    semver: [{\n      include: '@whitespace'\n    }, [':', 'delimiter'], [/\\d*\\.\\d*\\.\\d*/, {\n      token: 'number.semver',\n      bracket: '@close',\n      next: '@pop'\n    }]],\n    whitespace: [[/[ \\t\\r\\n]+/, 'white']]\n  }\n};"],"names":["conf","comments","lineComment","brackets","autoClosingPairs","open","close","surroundingPairs","folding","markers","start","RegExp","end","language","tokenPostfix","ignoreCase","keywords","typeKeywords","operators","symbols","tokenizer","root","token","bracket","next","cases","include","quoted_identifier","space_identifier_until_period","identifier_until_period","identifier_rest","semver","whitespace"],"sourceRoot":""}